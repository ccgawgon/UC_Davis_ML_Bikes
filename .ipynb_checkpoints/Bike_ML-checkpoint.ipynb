{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f3a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper function\n",
    "def findMinMax(data):\n",
    "  q1 = data.quantile(0.25)\n",
    "  q3 = data.quantile(0.75)\n",
    "  min = q1 - 1.5 * (q3 - q1)\n",
    "  max = q3 + 1.5 * (q3 - q1)\n",
    "  return min, max\n",
    "\n",
    "# Function to help us visualize the outliers. Produce boxplot and print out outliers\n",
    "def getOutliers(data, features):\n",
    "  for i, feature in enumerate(features, 1):\n",
    "    plt.subplot(1,len(features),i)\n",
    "    data[[feature]].boxplot()\n",
    "    \n",
    "    min, max = findMinMax(data[feature])\n",
    "    outliers_lower = data[feature] < min\n",
    "    outliers_upper = data[feature] > max\n",
    "    \n",
    "    if outliers_lower.any():\n",
    "      print(feature, \"- Lower outliers:\\n\", data.loc[outliers_lower, feature])\n",
    "    if outliers_upper.any():\n",
    "      print(feature, \"- Upper outliers:\\n\", data.loc[outliers_upper, feature])\n",
    "\n",
    "  plt.show()\n",
    "  \n",
    "\n",
    "# return az set of data with outliers removed\n",
    "def removeOutliers(data, features):\n",
    "  removeIdx = pd.Series([False] * len(data))\n",
    "  for i, feature in enumerate(features):\n",
    "    min, max = findMinMax(data[feature])\n",
    "    outliers_lower = data[feature] < min\n",
    "    outliers_upper = data[feature] > max\n",
    "    \n",
    "    removeIdx = removeIdx | outliers_lower | outliers_upper\n",
    "\n",
    "  return newData.loc[~removeIdx]\n",
    "  \n",
    "\n",
    "\n",
    "# Testing code\n",
    "data = pd.DataFrame(pd.read_csv('./SeoulBikeData.csv'))\n",
    "features = ['Rented Bike Count', 'Wind speed (m/s)']\n",
    "\n",
    "getOutliers(data, features)\n",
    "\n",
    "newData = removeOutliers(data, features)\n",
    "getOutliers(newData, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e6a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.DataFrame(pd.read_csv('./SeoulBikeData.csv'))\n",
    "\n",
    "# Remove rows with non-functioning day / no bike rented\n",
    "functioningDay = data['Functioning Day'] == 'Yes'\n",
    "data = data.loc[functioningDay]\n",
    "\n",
    "# Dropping some features:\n",
    "# Date: can't process and we already have the holiday feature\n",
    "# Dew temp: not relevant\n",
    "# Functioning day: already process\n",
    "data = data.drop(columns=['Date', 'Dew point temperature', 'Functioning Day'])\n",
    "\n",
    "\n",
    "# One Hot Encode categorical features\n",
    "# Hour should be categorical too. Not sure how to handle it yet\n",
    "data = pd.get_dummies(data, columns=['Seasons'], dtype=int)\n",
    "data = pd.get_dummies(data, columns=['Holiday'], dtype=int, drop_first=True)\n",
    "\n",
    "\n",
    "getOutliers(data, ['Rented Bike Count', 'Temperature', 'Humidity', 'Wind speed', 'Visibility', 'Solar Radiation', 'Rainfall', 'Snowfall'])\n",
    "\n",
    "# It seems like every rainy or snowy days are counted as outliers because the weather is normal most of the time.\n",
    "# Therefore, not going to remove outliers for Rainfall and Snowfall\n",
    "\n",
    "# A lot of outliers for Solar Radiation. We can test this out with our models. For now, not removing outliers for this one\n",
    "\n",
    "# Around 150 outliers for Rented Bike Count and Wind Speed. Remove outliers for now\n",
    "\n",
    "data = removeOutliers(data, ['Rented Bike Count', 'Temperature', 'Humidity', 'Wind speed', 'Visibility'])\n",
    "data = data.reset_index(drop=True)\n",
    "print(data)\n",
    "\n",
    "\n",
    "# Splitting data between categorical and numericals set for standardization\n",
    "categoricalFeatures = ['Hour', 'Seasons_Autumn', 'Seasons_Spring', 'Seasons_Summer', 'Seasons_Winter', 'Holiday_No Holiday']\n",
    "numericalFeatures = ['Rented Bike Count', 'Temperature', 'Humidity', 'Wind speed', 'Visibility', 'Solar Radiation', 'Rainfall', 'Snowfall']\n",
    "categoricalValues = data[categoricalFeatures]\n",
    "standardizedData = data.drop(columns=categoricalFeatures)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(standardizedData)\n",
    "standardizedData = scaler.transform(standardizedData)\n",
    "standardizedData = pd.DataFrame(standardizedData)\n",
    "standardizedData.columns = numericalFeatures\n",
    "\n",
    "standardizedData = pd.concat([standardizedData, categoricalValues], axis=1)\n",
    "print(standardizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0aeef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "# Note, need to modify X as appropriate for the different types of regression by adding column of 1's or any other parameters as neccessary\n",
    "def perform_training(X, y, folds, test_size=0.25, degrees=[1, 2], alphas=[0.0001, 0.001, 0.01]):\n",
    "    # Define number of folds for cross-validation\n",
    "    kf = KFold(folds)\n",
    "\n",
    "    # Initialize lists to store results for variance, bias2s, total_error, and models\n",
    "    # FINISH \n",
    "    \n",
    "    total_error = [] # list for total_error\n",
    "    models = [] # list for models\n",
    "    mses = []\n",
    "\n",
    "    # Features are already standardized \n",
    "\n",
    "    \n",
    "    for degree in degrees:\n",
    "        # create polynomial features\n",
    "        poly = PolynomialFeatures(degree=degree)\n",
    "        X_poly = poly.fit_transform(X)\n",
    "        \n",
    "        for alpha in alphas:\n",
    "            # Store MSEs for this configuration, save across models\n",
    "            fold_mses = []\n",
    "            \n",
    "            # Perform cross-validation\n",
    "            for train_index, test_index in kf.split(X_poly):\n",
    "                # Split data into training and testing sets for this fold\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "                # stochastic gradient descent with L2 aka ridge regression\n",
    "                model = SGDRegressor(\n",
    "                                loss='squared_loss', \n",
    "                                penalty='l2', \n",
    "                                alpha=alpha, \n",
    "                                max_iter=100, \n",
    "                                eta0=0.01, \n",
    "                                random_state=42\n",
    "                            )\n",
    "                # Train and predict\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "        \n",
    "                # Calculate MSE for new model prediction\n",
    "                mse = mean_squared_error(y_pred, y_test)\n",
    "                fold_mses.append(mse)\n",
    "                \n",
    "            # # Append results to lists\n",
    "            # # FINISH\n",
    "            # mses.append(mse)\n",
    "            # models.append(model)\n",
    "\n",
    "            # avg mean across the folds for curr degree and alpha\n",
    "            avg_mse = np.mean(fold_mses)\n",
    "            \n",
    "            # Updating the best model if current is better\n",
    "            if avg_mse < best_mse:\n",
    "                best_mse = avg_mse\n",
    "                best_model = model\n",
    "                best_degree = degree\n",
    "                best_alpha = alpha\n",
    "    \n",
    "    # print the total_error of the best model\n",
    "    min_error_index = np.argmin(mses)\n",
    "    best_model = models[min_error_index]\n",
    "    mse = mses[min_error_index]\n",
    "    \n",
    "    print(f\"Best Degree: {best_degree}\")\n",
    "    print(f\"Best Alpha: {best_alpha}\")\n",
    "    print(f\"Best Mean Squared Error: {best_mse}\")\n",
    "    \n",
    "    return best_model, best_degree, best_alpha\n",
    "\n",
    "# Testing Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188275cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =   # From the previous preprocessing function\n",
    "\n",
    "X = data.drop('Rented Bike Count', axis=1)\n",
    "y = data['Rented Bike Count']\n",
    "\n",
    "best_model, best_degree, best_alpha = perform_training(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb977b-f6bf-45f1-bb5d-eeec764bc3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
